{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOCuxgaCN77Zvj/Sa1DymOG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["# import os\n","# import numpy as np\n","# import librosa\n","# from sklearn.model_selection import train_test_split\n","# from tensorflow.keras.models import Sequential\n","# from tensorflow.keras.layers import Conv2D, MaxPooling2D, LSTM, Dense, Dropout, TimeDistributed, Flatten\n","# from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n","# from tensorflow.keras.optimizers import Adam\n","# from google.colab import drive\n","# from tensorflow.keras.utils import to_categorical\n","\n","# # Set the paths to the data files\n","# drive.mount('/content/drive')\n","\n","# angry_path = '/content/drive/My Drive/Colab Notebooks/Emotion_Recognization/Dataset/Angry'\n","# calm_path = '/content/drive/My Drive/Colab Notebooks/Emotion_Recognization/Dataset/Calm'\n","# neutral_path = '/content/drive/My Drive/Colab Notebooks/Emotion_Recognization/Dataset/Neutral'\n","# happy_path = '/content/drive/My Drive/Colab Notebooks/Emotion_Recognization/Dataset/Happy'\n","# sad_path = '/content/drive/My Drive/Colab Notebooks/Emotion_Recognization/Dataset/Sad'\n","\n","# # Define the number of MFCCs (Mel Frequency Cepstral Coefficients) to extract from each audio file\n","# num_mfcc = 40\n","\n","# # Define a fixed length for each feature matrix\n","# max_len = 500\n","\n","# # Define a function to extract the MFCCs from an audio file\n","# def extract_features(file_path):\n","#     y, sr = librosa.load(file_path, sr=None)\n","#     mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=num_mfcc)\n","#     return mfccs\n","\n","# # Load the data into memory\n","# X = []\n","# y = []\n","# for path, emotion in [(angry_path, 0), (calm_path, 1), (neutral_path, 2), (happy_path, 3), (sad_path, 4)]:\n","#     for file in os.listdir(path):\n","#         file_path = os.path.join(path, file)\n","#         mfccs = extract_features(file_path)\n","#         if len(mfccs.T) <= max_len:\n","#             pad_width = max_len - len(mfccs.T)\n","#             mfccs = np.pad(mfccs.T, pad_width=((0, pad_width), (0, 0)), mode='constant')\n","#             X.append(mfccs)\n","#             y.append(emotion)\n","\n","# X = np.array(X)\n","# y = np.array(y)\n","\n","# # Convert the target labels to one-hot encoded vectors\n","# y = to_categorical(y)\n","\n","# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# # Reshape the data to fit the RNN input shape\n","# X_train = np.expand_dims(X_train, axis=-1)\n","# X_test = np.expand_dims(X_test, axis=-1)\n","\n","# # Define the model architecture\n","# model = Sequential()\n","# model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(max_len, num_mfcc, 1)))\n","# model.add(MaxPooling2D((2, 2)))\n","# model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n","# model.add(MaxPooling2D((2, 2)))\n","# model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n","# model.add(MaxPooling2D((2, 2)))\n","# model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n","# model.add(MaxPooling2D((2, 2)))\n","# model.add(TimeDistributed(Flatten()))\n","# model.add(Dropout(0.5))\n","# model.add(Dense(512, activation='relu'))\n","# model.add(LSTM(128, dropout=0.5))\n","# model.add(Dense(5, activation='softmax'))\n","\n","# # Compile the model\n","# model.compile(optimizer=Adam(learning_rate=1e-4),\n","#               loss='categorical_crossentropy',\n","#               metrics=['accuracy'])\n","\n","# # Define a callback for TensorBoard\n","# tensorboard_callback = TensorBoard(log_dir='./logs')\n","\n","# # Define early stopping\n","# early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.001, patience=10, verbose=1, mode='auto',\n","#                                baseline=None, restore_best_weights=True)\n","\n","# # Train the model\n","# history = model.fit(X_train, y_train,\n","# validation_data=(X_test, y_test),\n","# epochs=50, batch_size=32,\n","# callbacks=[early_stopping, tensorboard_callback])\n","\n","# #Save the model\n","# model.save('my_model.h5')\n","\n","# #Evaluate the model on test data\n","# test_loss, test_acc = model.evaluate(X_test, y_test)\n","\n","# print('Test accuracy:', test_acc)"],"metadata":{"id":"OoUfS0-ErQyQ","executionInfo":{"status":"ok","timestamp":1681921369194,"user_tz":-540,"elapsed":14,"user":{"displayName":"Md Javed Ahmed (Shanto)","userId":"17961206760350746278"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import librosa\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, LSTM, Dense, Dropout, TimeDistributed, Flatten\n","from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n","from tensorflow.keras.optimizers import Adam\n","from google.colab import drive\n","from tensorflow.keras.utils import to_categorical\n","\n","# Set the paths to the data files\n","drive.mount('/content/drive')\n","\n","angry_path = '/content/drive/My Drive/Colab Notebooks/Emotion_Recognization/Dataset/Angry'\n","calm_path = '/content/drive/My Drive/Colab Notebooks/Emotion_Recognization/Dataset/Calm'\n","neutral_path = '/content/drive/My Drive/Colab Notebooks/Emotion_Recognization/Dataset/Neutral'\n","happy_path = '/content/drive/My Drive/Colab Notebooks/Emotion_Recognization/Dataset/Happy'\n","sad_path = '/content/drive/My Drive/Colab Notebooks/Emotion_Recognization/Dataset/Sad'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UK-50-OCbFkv","executionInfo":{"status":"ok","timestamp":1681921392231,"user_tz":-540,"elapsed":23047,"user":{"displayName":"Md Javed Ahmed (Shanto)","userId":"17961206760350746278"}},"outputId":"7049ab91-e2e6-4e3f-918d-90bbcacb9bcd"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Define the number of MFCCs (Mel Frequency Cepstral Coefficients) to extract from each audio file\n","num_mfcc = 40\n","\n","# Define a fixed length for each feature matrix\n","max_len = 500\n","\n","# Define a function to extract the MFCCs from an audio file\n","def extract_features(file_path):\n","    y, sr = librosa.load(file_path, sr=None)\n","    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=num_mfcc)\n","    return mfccs\n","\n","# Load the data into memory\n","X = []\n","y = []\n","for path, emotion in [(angry_path, 0), (calm_path, 1), (neutral_path, 2), (happy_path, 3), (sad_path, 4)]:\n","    for file in os.listdir(path):\n","        file_path = os.path.join(path, file)\n","        mfccs = extract_features(file_path)\n","        if len(mfccs.T) <= max_len:\n","            pad_width = max_len - len(mfccs.T)\n","            mfccs = np.pad(mfccs.T, pad_width=((0, pad_width), (0, 0)), mode='constant')\n","            X.append(mfccs)\n","            y.append(emotion)\n","\n","X = np.array(X)\n","y = np.array(y)\n","\n","# Convert the target labels to one-hot encoded vectors\n","y = to_categorical(y)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Reshape the data to fit the RNN input shape\n","X_train = np.expand_dims(X_train, axis=-1)\n","X_test = np.expand_dims(X_test, axis=-1)\n"],"metadata":{"id":"rYu70JKeaqmc","executionInfo":{"status":"ok","timestamp":1681921687499,"user_tz":-540,"elapsed":295271,"user":{"displayName":"Md Javed Ahmed (Shanto)","userId":"17961206760350746278"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Define the model architecture\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(max_len, num_mfcc, 1)))\n","model.add(MaxPooling2D((2, 2)))\n","model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n","model.add(MaxPooling2D((2, 2)))\n","model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n","model.add(MaxPooling2D((2, 2)))\n","model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n","model.add(MaxPooling2D((2, 2)))\n","model.add(TimeDistributed(Flatten()))\n","model.add(Dropout(0.5))\n","model.add(Dense(512, activation='relu'))\n","model.add(LSTM(128, dropout=0.5))\n","model.add(Dense(5, activation='softmax'))\n"],"metadata":{"id":"dwcPfiTbavUE","executionInfo":{"status":"ok","timestamp":1681921691217,"user_tz":-540,"elapsed":3727,"user":{"displayName":"Md Javed Ahmed (Shanto)","userId":"17961206760350746278"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Compile the model\n","model.compile(optimizer=Adam(learning_rate=1e-4),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Define a callback for TensorBoard\n","tensorboard_callback = TensorBoard(log_dir='./logs')\n","\n","# Define early stopping\n","early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.001, patience=10, verbose=1, mode='auto',\n","                               baseline=None, restore_best_weights=True)"],"metadata":{"id":"C27yNlD2a2kF","executionInfo":{"status":"ok","timestamp":1681921691217,"user_tz":-540,"elapsed":12,"user":{"displayName":"Md Javed Ahmed (Shanto)","userId":"17961206760350746278"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","history = model.fit(X_train, y_train,\n","validation_data=(X_test, y_test),\n","epochs=100, batch_size=32,\n","callbacks=[early_stopping, tensorboard_callback])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mLCJmVmWa5t2","outputId":"14fa8075-d1dc-4a7b-c63d-1c49c604eaa5","executionInfo":{"status":"ok","timestamp":1681921933231,"user_tz":-540,"elapsed":241428,"user":{"displayName":"Md Javed Ahmed (Shanto)","userId":"17961206760350746278"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","187/187 [==============================] - 23s 35ms/step - loss: 1.4837 - accuracy: 0.2504 - val_loss: 1.4298 - val_accuracy: 0.3394\n","Epoch 2/100\n","187/187 [==============================] - 5s 25ms/step - loss: 1.2654 - accuracy: 0.3954 - val_loss: 1.1245 - val_accuracy: 0.4527\n","Epoch 3/100\n","187/187 [==============================] - 5s 27ms/step - loss: 1.0542 - accuracy: 0.5043 - val_loss: 1.0259 - val_accuracy: 0.4983\n","Epoch 4/100\n","187/187 [==============================] - 5s 27ms/step - loss: 1.0021 - accuracy: 0.5345 - val_loss: 1.0642 - val_accuracy: 0.5017\n","Epoch 5/100\n","187/187 [==============================] - 5s 26ms/step - loss: 0.9643 - accuracy: 0.5623 - val_loss: 0.9518 - val_accuracy: 0.5674\n","Epoch 6/100\n","187/187 [==============================] - 5s 29ms/step - loss: 0.9346 - accuracy: 0.5831 - val_loss: 0.9723 - val_accuracy: 0.5808\n","Epoch 7/100\n","187/187 [==============================] - 5s 26ms/step - loss: 0.9118 - accuracy: 0.5933 - val_loss: 0.9096 - val_accuracy: 0.6264\n","Epoch 8/100\n","187/187 [==============================] - 5s 27ms/step - loss: 0.8539 - accuracy: 0.6389 - val_loss: 0.7902 - val_accuracy: 0.6875\n","Epoch 9/100\n","187/187 [==============================] - 5s 28ms/step - loss: 0.8244 - accuracy: 0.6550 - val_loss: 0.7980 - val_accuracy: 0.6861\n","Epoch 10/100\n","187/187 [==============================] - 5s 27ms/step - loss: 0.7929 - accuracy: 0.6758 - val_loss: 0.7492 - val_accuracy: 0.7022\n","Epoch 11/100\n","187/187 [==============================] - 5s 27ms/step - loss: 0.7597 - accuracy: 0.6861 - val_loss: 0.7059 - val_accuracy: 0.7203\n","Epoch 12/100\n","187/187 [==============================] - 5s 26ms/step - loss: 0.7362 - accuracy: 0.6961 - val_loss: 0.7027 - val_accuracy: 0.7190\n","Epoch 13/100\n","187/187 [==============================] - 5s 27ms/step - loss: 0.7131 - accuracy: 0.7097 - val_loss: 0.6702 - val_accuracy: 0.7237\n","Epoch 14/100\n","187/187 [==============================] - 5s 27ms/step - loss: 0.6950 - accuracy: 0.7137 - val_loss: 0.7194 - val_accuracy: 0.7150\n","Epoch 15/100\n","187/187 [==============================] - 5s 25ms/step - loss: 0.6678 - accuracy: 0.7342 - val_loss: 0.6821 - val_accuracy: 0.7264\n","Epoch 16/100\n","187/187 [==============================] - 5s 27ms/step - loss: 0.6617 - accuracy: 0.7255 - val_loss: 0.7577 - val_accuracy: 0.6968\n","Epoch 17/100\n","187/187 [==============================] - 5s 29ms/step - loss: 0.6286 - accuracy: 0.7448 - val_loss: 0.6215 - val_accuracy: 0.7438\n","Epoch 18/100\n","187/187 [==============================] - 5s 26ms/step - loss: 0.6192 - accuracy: 0.7505 - val_loss: 0.6264 - val_accuracy: 0.7465\n","Epoch 19/100\n","187/187 [==============================] - 5s 27ms/step - loss: 0.6083 - accuracy: 0.7599 - val_loss: 0.6476 - val_accuracy: 0.7337\n","Epoch 20/100\n","187/187 [==============================] - 5s 28ms/step - loss: 0.5859 - accuracy: 0.7672 - val_loss: 0.6173 - val_accuracy: 0.7646\n","Epoch 21/100\n","187/187 [==============================] - 5s 27ms/step - loss: 0.5870 - accuracy: 0.7634 - val_loss: 0.5947 - val_accuracy: 0.7612\n","Epoch 22/100\n","187/187 [==============================] - 5s 28ms/step - loss: 0.5596 - accuracy: 0.7726 - val_loss: 0.6367 - val_accuracy: 0.7606\n","Epoch 23/100\n","187/187 [==============================] - 5s 26ms/step - loss: 0.5458 - accuracy: 0.7781 - val_loss: 0.6586 - val_accuracy: 0.7612\n","Epoch 24/100\n","187/187 [==============================] - 5s 27ms/step - loss: 0.5463 - accuracy: 0.7869 - val_loss: 0.6352 - val_accuracy: 0.7478\n","Epoch 25/100\n","187/187 [==============================] - 5s 28ms/step - loss: 0.5014 - accuracy: 0.8066 - val_loss: 0.6545 - val_accuracy: 0.7726\n","Epoch 26/100\n","187/187 [==============================] - 5s 26ms/step - loss: 0.5130 - accuracy: 0.7959 - val_loss: 0.5560 - val_accuracy: 0.7814\n","Epoch 27/100\n","187/187 [==============================] - 5s 27ms/step - loss: 0.4931 - accuracy: 0.8078 - val_loss: 0.6432 - val_accuracy: 0.7532\n","Epoch 28/100\n","187/187 [==============================] - 5s 27ms/step - loss: 0.4705 - accuracy: 0.8144 - val_loss: 0.5562 - val_accuracy: 0.7854\n","Epoch 29/100\n","187/187 [==============================] - 5s 27ms/step - loss: 0.4650 - accuracy: 0.8231 - val_loss: 0.6721 - val_accuracy: 0.7418\n","Epoch 30/100\n","187/187 [==============================] - 5s 28ms/step - loss: 0.4588 - accuracy: 0.8214 - val_loss: 0.5661 - val_accuracy: 0.7800\n","Epoch 31/100\n","187/187 [==============================] - 5s 28ms/step - loss: 0.4375 - accuracy: 0.8338 - val_loss: 0.5736 - val_accuracy: 0.7834\n","Epoch 32/100\n","187/187 [==============================] - 5s 26ms/step - loss: 0.4090 - accuracy: 0.8444 - val_loss: 0.6206 - val_accuracy: 0.7632\n","Epoch 33/100\n","187/187 [==============================] - 5s 28ms/step - loss: 0.4130 - accuracy: 0.8412 - val_loss: 0.5689 - val_accuracy: 0.7968\n","Epoch 34/100\n","187/187 [==============================] - 5s 27ms/step - loss: 0.3970 - accuracy: 0.8450 - val_loss: 0.5381 - val_accuracy: 0.8068\n","Epoch 35/100\n","187/187 [==============================] - 5s 27ms/step - loss: 0.3856 - accuracy: 0.8492 - val_loss: 0.5535 - val_accuracy: 0.7840\n","Epoch 36/100\n","187/187 [==============================] - 5s 28ms/step - loss: 0.3568 - accuracy: 0.8621 - val_loss: 0.5779 - val_accuracy: 0.7941\n","Epoch 37/100\n","187/187 [==============================] - 5s 27ms/step - loss: 0.3685 - accuracy: 0.8598 - val_loss: 0.5725 - val_accuracy: 0.7961\n","Epoch 38/100\n","187/187 [==============================] - 5s 28ms/step - loss: 0.3412 - accuracy: 0.8694 - val_loss: 0.5515 - val_accuracy: 0.7988\n","Epoch 39/100\n","187/187 [==============================] - 5s 27ms/step - loss: 0.3316 - accuracy: 0.8769 - val_loss: 0.5564 - val_accuracy: 0.7941\n","Epoch 40/100\n","187/187 [==============================] - 5s 27ms/step - loss: 0.3138 - accuracy: 0.8863 - val_loss: 0.5801 - val_accuracy: 0.7954\n","Epoch 41/100\n","187/187 [==============================] - 5s 29ms/step - loss: 0.3022 - accuracy: 0.8883 - val_loss: 0.6256 - val_accuracy: 0.7753\n","Epoch 42/100\n","187/187 [==============================] - 5s 26ms/step - loss: 0.2784 - accuracy: 0.8965 - val_loss: 0.5735 - val_accuracy: 0.8015\n","Epoch 43/100\n","187/187 [==============================] - 5s 28ms/step - loss: 0.2658 - accuracy: 0.9039 - val_loss: 0.6177 - val_accuracy: 0.7901\n","Epoch 44/100\n","187/187 [==============================] - ETA: 0s - loss: 0.2605 - accuracy: 0.9056Restoring model weights from the end of the best epoch: 34.\n","187/187 [==============================] - 5s 28ms/step - loss: 0.2605 - accuracy: 0.9056 - val_loss: 0.6523 - val_accuracy: 0.8001\n","Epoch 44: early stopping\n"]}]},{"cell_type":"code","source":["#Save the model\n","model.save('my_model.h5')\n","\n","#Evaluate the model on test data\n","test_loss, test_acc = model.evaluate(X_test, y_test)\n","\n","print('Test accuracy:', test_acc)"],"metadata":{"id":"CFzi8amBa9JL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681921957040,"user_tz":-540,"elapsed":23819,"user":{"displayName":"Md Javed Ahmed (Shanto)","userId":"17961206760350746278"}},"outputId":"927c9442-05e1-4f94-dd53-0b0f99984e38"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["47/47 [==============================] - 1s 11ms/step - loss: 0.5381 - accuracy: 0.8068\n","Test accuracy: 0.8068410754203796\n"]}]}]}